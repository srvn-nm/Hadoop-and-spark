# BigData Solution for Hadoop and Spark.
### Scale your data management by distributing workload and storage on Hadoop and Spark Clusters, explore and transform your data in Jupyter Notebook.

## About The Project

Purpose for this tutorial is to show how to get started with Hadoop, Spark and Jupyter for your BigData solution, deployed as Docker Containers.

## Pre-requisite
- Apple Silicon might use arm64 branch to install.
- Ensure Docker is installed.

## Start
Execute `bash master-build.sh` to start the the build and start the containers.

## Stop
Execute `bash master-delete.sh` to stop the containers.

### Hadoop
Access Hadoop UI on ' http://localhost:9870 '

### Spark
Access Spark Master UI on ' http://localhost:8080 '

### Jupyter
Access Jupyter UI on ' http://localhost:8888 '

# Hadoop-and-spark
